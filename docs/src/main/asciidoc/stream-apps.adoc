[[dev-stream-apps]]
= Developing Stream applications

--
In this section we will cover how to create, test and run Spring Cloud Stream applications locally and on Cloud Foundry.  We will also show how to map these applications into Spring Cloud Data Flow and deploy them locally and on Cloud Foundry.
--

[[prebuilt-apps]]
== Prebuilt applications
The link:http://cloud.spring.io/spring-cloud-stream-app-starters/[Spring Cloud Stream App Starters]
project provides many applications that you can start using right away.
For example, there is an http source application that will recive messages
posted to an http endpoint and publish the data to the messaging middleware.
Each existing application comes in three variations, one for each type of
messaging middlware that is supported.  The current supported messaging
middleware systems are RabbitMQ, Apache Kafka 0.9 and Apache Kafka 0.10.  All the
applications are based on
link:https://projects.spring.io/spring-boot/[Spring Boot] and
link:https://cloud.spring.io/spring-cloud-stream/[Spring Cloud Stream].

Applications are published as a Maven artifact as well as a Docker image.
The Maven artifacts are published to Maven central and the link:http://repo.spring.io/release[Spring Release Repository]
for GA releases.  Milestone and snapshot releases are published to the
link:http://repo.spring.io/milestone[Spring Milestone] and link:http://repo.spring.io/release[Snapshot] repositories respectfully.  Docker images are pushed
to link:https://hub.docker.com/u/springcloudstream/[Docker Hub].

We will be using the maven artifacts for our examples.  The root location
of the Spring Repository that hosts the GA artifacts of prebuilt applications is
link:http://repo.spring.io/libs-release/org/springframework/cloud/stream/app/

[[rabbitmq-prereq]]
== Installing RabbitMQ
In this example we will be using RabbitMQ as the messaging middleware.  Follow
the directions on link:https://www.rabbitmq.com/download.html[rabbitmq.com] for
your platform.  Then install the link:https://www.rabbitmq.com/management.html[management plugin]

[[running-prebuilt-apps]]
== Running existing applications
In this example we will run the http source application and the log sink application.  The two applications will use RabbitMQ to communicate.

First, download each application

[source,bash]
----
wget http://repo.spring.io/libs-release/org/springframework/cloud/stream/app/http-source-rabbit/1.1.2.RELEASE/http-source-rabbit-1.1.2.RELEASE.jar

wget http://repo.spring.io/libs-release/org/springframework/cloud/stream/app/log-sink-rabbit/1.1.1.RELEASE/log-sink-rabbit-1.1.1.RELEASE.jar
----

These are Spring Boot applications that include the
link:http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready.html[Spring Boot Actuator]
and the
link:http://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-security.html[Spring Security Starter].  You can specify link:https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html[common Spring Boot properties] to configure each application.  The properties that
are specific to each application are listed in link:http://docs.spring.io/spring-cloud-stream-app-starters/docs/Avogadro.SR1/reference/html/[documentation for Spring App Starters], for example the
link:http://docs.spring.io/spring-cloud-stream-app-starters/docs/Avogadro.SR1/reference/html/sources.html#spring-cloud-stream-modules-http-source[http source] and the
link:http://docs.spring.io/spring-cloud-stream-app-starters/docs/Avogadro.SR1/reference/html/spring-cloud-stream-modules-sinks.html#spring-cloud-stream-modules-log-sink[log sink]

Now lets run the http source application.  Just for fun let's pass in a few options as system properties

[source,bash]
----
java -Dserver.port=8123 -Dhttp.pathPattern=/data -Dspring.cloud.stream.bindings.output.destination=sensorData -jar http-source-rabbit-1.1.2.RELEASE.jar

java -Dlog.level=WARN -Dspring.cloud.stream.bindings.input.destination=sensorData -jar log-sink-rabbit-1.1.1.RELEASE.jar 
----


== Creating and testing a custom processor application

create, uppercase and unit test it.

run cmd line equivalent of http | uppercase | log

== Mapping the application to Spring Cloud Data Flow

register apps, create stream and deploy it locally

== Integration testing locally

use the new integration testing library locally

== Integration testing on Cloud Foundry

== Deploying on Cloud Foundry

[[dev-customizing-stream-apps]]
= Customizing Stream applications

== Changing the messaging middleware

== Changing the serialization

== Changing the number of instances

no partitioning, basic scale up.

== Composing applications


[[dev-multiple-streamstopologies]]
= Collaborating streams

Show More complex topologies

== real-time analytics

== Fan in/Fan out

[[dev-data-partitioning]]
= Data Partitioning


