[[dev-stream-apps]]
= Developing Stream applications

--
In this section we will cover how to create, test and run Spring Cloud Stream
applications locally and on Cloud Foundry.  We will also show how to map these
applications into Spring Cloud Data Flow and deploy them locally and on
Cloud Foundry.
--

[[prebuilt-apps]]
== Prebuilt applications
The link:http://cloud.spring.io/spring-cloud-stream-app-starters/[Spring Cloud Stream App Starters]
project provides many applications that you can start using right away.
For example, there is an http source application that will recive messages
posted to an http endpoint and publish the data to the messaging middleware.
Each existing application comes in three variations, one for each type of
messaging middlware that is supported.  The current supported messaging
middleware systems are RabbitMQ, Apache Kafka 0.9 and Apache Kafka 0.10.
All the applications are based on
link:https://projects.spring.io/spring-boot/[Spring Boot] and
link:https://cloud.spring.io/spring-cloud-stream/[Spring Cloud Stream].

Applications are published as a Maven artifact as well as a Docker image.
The Maven artifacts are published to Maven central and the link:http://repo.spring.io/release[Spring Release Repository]
for GA releases.  Milestone and snapshot releases are published to the
link:http://repo.spring.io/milestone[Spring Milestone] and link:http://repo.spring.io/snapshot[Snapshot] repositories respectfully.  Docker images are pushed
to link:https://hub.docker.com/u/springcloudstream/[Docker Hub].

We will be using the maven artifacts for our examples.  The root location
of the Spring Repository that hosts the GA artifacts of prebuilt applications is
link:http://repo.spring.io/release/org/springframework/cloud/stream/app/

[[rabbitmq-prereq]]
== Installing RabbitMQ
In this example we will be using RabbitMQ as the messaging middleware.  Follow
the directions on link:https://www.rabbitmq.com/download.html[rabbitmq.com] for
your platform.  Then install the link:https://www.rabbitmq.com/management.html[management plugin]

[[running-prebuilt-apps]]
== Running existing applications
In this example we will run the http source application and the log sink application.  The two applications will use RabbitMQ to communicate.

First, download each application

[source,bash]
----
wget http://repo.spring.io/snapshot/org/springframework/cloud/stream/app/http-source-rabbit/1.2.0.BUILD-SNAPSHOT/http-source-rabbit-1.2.0.BUILD-SNAPSHOT.jar

wget http://repo.spring.io/release/org/springframework/cloud/stream/app/log-sink-rabbit/1.1.1.RELEASE/log-sink-rabbit-1.1.1.RELEASE.jar

----

These are Spring Boot applications that include the
link:http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready.html[Spring Boot Actuator]
and the
link:http://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-security.html[Spring Security Starter].  You can specify link:https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html[common Spring Boot properties] to configure each application.  The properties
that are specific to each application are listed in
link:http://docs.spring.io/spring-cloud-stream-app-starters/docs/Avogadro.SR1/reference/html/[documentation for Spring App Starters], for example the
link:http://docs.spring.io/spring-cloud-stream-app-starters/docs/Avogadro.SR1/reference/html/sources.html#spring-cloud-stream-modules-http-source[http source] and the
link:http://docs.spring.io/spring-cloud-stream-app-starters/docs/Avogadro.SR1/reference/html/spring-cloud-stream-modules-sinks.html#spring-cloud-stream-modules-log-sink[log sink]

Now lets run the http source application.  Just for fun let's pass in a few options as system properties

[source,bash]
----
java -Dserver.port=8123 -Dhttp.path-pattern=/data -Dspring.cloud.stream.bindings.output.destination=sensorData -jar http-source-rabbit-1.2.0.BUILD-SNAPSHOT.jar

----

The property `server.port` comes from Spring Boot's Web support and the property `http.path-pattern` comes from the HTTP source application - link:https://github.com/spring-cloud-stream-app-starters/http/blob/master/spring-cloud-starter-stream-source-http/src/main/java/org/springframework/cloud/stream/app/http/source/HttpSourceProperties.java[HttpSourceProperties].  The http source app will be listening on port 8123 under the the path `/data`.

The property `spring.cloud.stream.bindings.output.destination` comes from the
Spring Cloud Stream library and is the name of the messaging destination that
will be shared between the source and the sink.  The string `output` in this
property is the name of the Spring Integration channel whose contents will be
published to the messaging middleware.  The literal string `output` is baked into the convenience class link:http://docs.spring.io/spring-cloud-stream/docs/current/reference/htmlsingle/#__literal_source_literal_literal_sink_literal_and_literal_processor_literal[Source] for use in an application that has a single
outbound channel.

Now lets run the log sink application and change the logging level to WARN.

[source,bash]
----
java -Dlog.level=WARN -Dspring.cloud.stream.bindings.input.destination=sensorData -jar log-sink-rabbit-1.1.1.RELEASE.jar 
----

The property `log.level` comes from the log sink application - link:https://github.com/spring-cloud-stream-app-starters/log/blob/master/spring-cloud-starter-stream-sink-log/src/main/java/org/springframework/cloud/stream/app/log/sink/LogSinkProperties.java[LogSinkProperties].

The value of the property `spring.cloud.stream.bindings.input.destination` is
set to `sensorData` so that the source and sink applications can communicate
to each other.  The string `input` in this property is the name of the Spring
Integration channel where messages will be received from the messaging
middleware.  The literal string `input` is baked into the convenience class
link:http://docs.spring.io/spring-cloud-stream/docs/current/reference/htmlsingle/#__literal_source_literal_literal_sink_literal_and_literal_processor_literal[Sink] for use in an application that has a single inbound channel.

Now lets post some content to the http source application

[source,bash]
----
curl -H "Content-Type: application/json" -X POST -d '{"id":"1","temperature":"100"}' http://localhost:8123/data
----

The log sink application will then show the following output

[source,bash]
----
2017-03-17 15:30:17.825  WARN 22710 --- [_qquaYekbQ0nA-1] log-sink                                 : {"id":"1","temperature":"100"}
----


== Creating and testing a custom processor application

Now let us create an application that does some processing on the output of the
http source and then send data to the log sink.  We will make use of the link:link:http://docs.spring.io/spring-cloud-stream/docs/current/reference/htmlsingle/#__literal_source_literal_literal_sink_literal_and_literal_processor_literal[Processor] convenience class that has both an inbound channel and an outbound channel.

Visit the link:https://start.spring.io/[Spring Initialzr] site and create a new
Maven project with the group name `io.spring.stream.sample` and the artifact name `transformer`.  In the dependencies text box, type `stream rabbit` to select the Spring Cloud Stream dependency that will use the RabbitMQ binder.

Unzip the project and bring the project into your favorite IDE.  Create a class called Transformer in the `io.spring.stream.sample` package with the following contents.

[source,java]
----

----

Then open the already created `TransformerApplicationTests` class.  


import static org.hamcrest.CoreMatchers.*;is



create, uppercase and unit test it.

run cmd line equivalent of http | uppercase | log

== Mapping the application to Spring Cloud Data Flow

register apps, create stream and deploy it locally

== Integration testing locally

use the new integration testing library locally

== Integration testing on Cloud Foundry

== Deploying on Cloud Foundry

[[dev-customizing-stream-apps]]
= Customizing Stream applications

== Changing the messaging middleware

== Changing the serialization

== Changing the number of instances

no partitioning, basic scale up.

== Composing applications


[[dev-multiple-streamstopologies]]
= Collaborating streams

Show More complex topologies
== Durability

in the case of rabbit, need to talk about requiredGroups on producer side
and consumerGroup on consumer side.


== real-time analytics

== Fan in/Fan out

[[dev-data-partitioning]]
= Data Partitioning


